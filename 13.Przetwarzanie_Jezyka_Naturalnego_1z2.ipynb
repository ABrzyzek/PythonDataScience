{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a29fbfd7-da0e-43bf-acff-be6b06c5256d",
   "metadata": {},
   "source": [
    "# Warsztaty Python w Data Science\n",
    "\n",
    "---\n",
    "## Przetwarzanie języka naturalnego - część 1 z 2  \n",
    "- ### Tokenizacja\n",
    "- ### Statystyki tekstu \n",
    "- ### Prosta Lematyzacja\n",
    "- ### Metryka TF-IDF\n",
    "- ### TF-IDF dla zlematyzowanego korpusu\n",
    "- ### Stoplista\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6088618f-9eae-4a03-b3ac-9b1298da9ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv('data/gumtree-2022-03-20.tsv', sep='\\t', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eaa1ca2-f7a3-4ecc-b3c0-fe3d2c05f1ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b307ae14-7404-40dc-b51f-0098df158953",
   "metadata": {},
   "source": [
    "---\n",
    "# Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2056b673-a3eb-44e7-9ab1-510ca18d1d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "opis = data['description'][6]\n",
    "opis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4ec11a-6ac7-4d94-be0b-fa7cc56b0ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def no_tags(s):\n",
    "    return re.sub(r'<[^<]+?>','',s)\n",
    "\n",
    "opis = no_tags(opis)\n",
    "opis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3b1433b-54ea-4910-9ff8-988d44895338",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "tokenizer = re.compile(r'[^ąąćęńłóóśśżżź\\w]+')\n",
    "tokenized = tokenizer.split(opis)\n",
    "str(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c41e2e-9f6c-4510-af8e-764534125114",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized = [ x.lower() for x in tokenized ]\n",
    "str(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b7e2fc7-7fd4-4582-b56a-737dac002875",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(opis):\n",
    "    opis = no_tags(opis)\n",
    "    tokenized = tokenizer.split(opis)\n",
    "    l = list(tokenized)\n",
    "    l = [ x.lower() for x in l ]\n",
    "    return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ead1f2-0181-4328-b9c5-aea20ddb6968",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "n=4\n",
    "for row in data.iterrows():\n",
    "    opis = row[1][2]\n",
    "    l = preprocessing(opis)\n",
    "    corpus.append(l)\n",
    "    n-=1\n",
    "    if n==0: break\n",
    "\n",
    "for opis in corpus:\n",
    "    print(opis)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2be049a-b842-4714-b952-7a4966a1f7b2",
   "metadata": {},
   "source": [
    "---\n",
    "# Statystyki tekstu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03c7acff-89b7-4a3d-b338-cd7837277d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = []\n",
    "for row in data.iterrows():\n",
    "    opis = row[1][2]\n",
    "    if type(opis) == str:\n",
    "        l = preprocessing(opis)\n",
    "        corpus.append(l)\n",
    "\n",
    "    \n",
    "print(f\"Mamy tekstów: {len(corpus)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abbce7f6-5a3d-45fa-9df9-4d2a9b3a73e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for t in corpus:\n",
    "    all_words += t\n",
    " \n",
    "print(f\"Mamy {len(all_words)} wyrazów\")\n",
    "all_words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b526686-93b2-46ff-a5ad-edf1bd82a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {}\n",
    "\n",
    "for w in all_words:\n",
    "    counter[w] = counter.get(w,0)+1\n",
    "\n",
    "print(f\"Mamy {len(counter.keys())} RÓŻNYCH wyrazów\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d43b69-d1ab-4fa1-85b9-8c5ee56c05a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_words= [ (word,cnt) for word,cnt in counter.items() ]\n",
    "counted_words[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3edae0b-221f-4a6a-b5cd-27f2e2f4dada",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "counted_words.sort(key=itemgetter(1), reverse=True)\n",
    "counted_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e75202f-d37f-45b5-a7d7-ae87c7052345",
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_words[-20:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddf69885-aa92-42fb-8df3-2315faca8b4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [ x[1] for x in counted_words ]\n",
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13177539-d388-44be-921f-48cb8e2488b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4789c7c-5de9-44dd-bb85-829e773716b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts[:175])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdaa8120-3e22-492c-a82c-de82d127f0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_words[165:175]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0811ff5-82db-49bd-a941-8ae6c0387b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "count_df = pd.DataFrame(counts[:120])\n",
    "count_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846769f6-7054-49e6-a81e-1e07f18af125",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "chart = sns.scatterplot(\n",
    "                     color='purple', \n",
    "                     data=count_df\n",
    "                    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a39f4378-e848-47e4-a763-fb7ca5084379",
   "metadata": {},
   "source": [
    "---\n",
    "# Prosta Lematyzacja"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a37625cc-1d8f-4822-ab32-19c121d684d1",
   "metadata": {},
   "source": [
    "## _Lematyzacja_ - sprowadzenie wyrazu do formy podstawowej tak aby różne formy tego wyrazu (*kot*, *kota*, *kotu*) były rozpatrywane jako ten sam wyraz (*kot*) \n",
    "\n",
    "https://sjp.pl/\n",
    "    \n",
    "Słownik SJP.PL\n",
    "Słownik języka polskiego, ortograficzny, wyrazów obcych i słownik do gier w jednym.\n",
    "\n",
    "Słownik jest rozwijany z myślą o zastosowaniu do sprawdzania pisowni w programach open-source, do gier słownych (np. literaki) i do użytku online jako kilka rodzajów słowników w jednym.\n",
    "\n",
    "Redakcją słownika zajmują się hobbyści.\n",
    "\n",
    "Słownik jest udostępniany na otwartych licencjach (różnych w zależności od wersji)."
   ]
  },
  {
   "cell_type": "raw",
   "id": "5d30a4ac-8ba1-41e8-9d7f-2f24c472b645",
   "metadata": {},
   "source": [
    "...\n",
    "mieszkaniec, mieszkańca, mieszkańcach, mieszkańcami, mieszkańce, mieszkańcem, mieszkańcom, mieszkańcowi, mieszkańców, mieszkańcu, mieszkańcy, mieszkańcze\n",
    "mieszkanie, mieszkania, mieszkaniach, mieszkaniami, mieszkaniem, mieszkaniom, mieszkaniu, mieszkań\n",
    "mieszkaniowy, mieszkaniowa, mieszkaniową, mieszkaniowe, mieszkaniowego, mieszkaniowej, mieszkaniowemu, mieszkaniowi, mieszkaniowo, mieszkaniowych, mieszkaniowym, \n",
    "mieszkaniowymi\n",
    "...\n",
    "(219.228 wyrazów, 4.295.200 form)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91f24d85-8d30-4405-829c-ee8448a00278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gzip\n",
    "import sys\n",
    "import re\n",
    "\n",
    "f = gzip.open('data/odm.txt.gz', 'rt', encoding='utf-8')\n",
    "dictionary = {}\n",
    "\n",
    "for x in f:\n",
    "    t = x.strip().split(',')\n",
    "    tt = [ x.strip().lower() for x in t]\n",
    "    for w in tt[1:]: \n",
    "        dictionary[w]=tt[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efccbcf5-08f5-48bc-bffd-0a6de3fe141c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lematize(w):\n",
    "    return dictionary.get(w,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c61bf88-da33-44d4-bbc6-0764e97f89ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpusl = [[ lematize(x) for x in l ] for l in corpus]\n",
    "for opis in corpusl[:7]:\n",
    "    print(opis)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933d6be5-7339-4c8f-94c6-d6993f971fea",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_words = []\n",
    "for t in corpusl:\n",
    "    all_words += t\n",
    " \n",
    "print(f\"Mamy {len(all_words)} wyrazów\")\n",
    "all_words[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62fce5f-1459-4e2f-93e8-9b19fc45b510",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = {}\n",
    "\n",
    "for w in all_words:\n",
    "    counter[w] = counter.get(w,0)+1\n",
    "\n",
    "print(f\"Mamy {len(counter.keys())} RÓŻNYCH wyrazów\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20fdf8dd-53ee-4829-a2b5-060322a9f560",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "counted_words= [ (word,cnt) for word,cnt in counter.items() ]\n",
    "counted_words.sort(key=itemgetter(1), reverse=True)\n",
    "counted_words[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40b023a9-28cf-485e-8275-4423bbb38e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = [ x[1] for x in counted_words ]\n",
    "len(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e18bd7-5971-445a-871b-f2ce8898a37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e234144b-9e77-4ec7-a6b9-d883722c50c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(counts[:105])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9764a987-fca2-438a-8322-8d98285fa5ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "counted_words[95:105]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b5b61d-6a2f-45a0-afa9-5ef13121171c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from pandas.plotting import register_matplotlib_converters\n",
    "register_matplotlib_converters()\n",
    "import matplotlib.dates as mdates\n",
    "\n",
    "counts = [ x[1] for x in counted_words ]\n",
    "count_df = pd.DataFrame(counts[:120])\n",
    "count_df\n",
    "\n",
    "plt.figure(figsize=(24,12))\n",
    "plt.style.use(\"dark_background\")\n",
    "\n",
    "chart = sns.scatterplot(\n",
    "        color='purple', \n",
    "        data=count_df\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6875eb-e638-444d-8be3-bd572afc5e17",
   "metadata": {},
   "source": [
    "---\n",
    "## Metryka TF-IDF\n",
    "ile razy występuję wyraz *i* w tekście *j*\n",
    "$${n}_{ij}$$ \n",
    " ### Term Frequency (TF)\n",
    " \n",
    " $${tf}_{ij} = \\frac{{n}_{ij}}{\\sum{k}{{n}_{ik}}}$$\n",
    " \n",
    " W tekście *j* sprawdzamy ile proporcjonalnie do całości występuje wyraz *i*\n",
    "### Inverted Document Frequency (IDF)\n",
    "\n",
    " $$idf_i = log \\frac{|D|}{ \\{ d: n_i \\in d \\}}$$\n",
    " \n",
    " licznik - liczba dokumentów\n",
    " \n",
    " mianownik - liczba dokumentów w którym wystapił wyraz *i*-ty "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daa1dddf-512a-43dd-8980-c564a971d246",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## [Dokumentacja do `TfidfVectorizer` z biblioteki Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1ef95b-7a6c-482c-81dd-70d392df4fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import pandas as pd\n",
    "\n",
    "vocabulary = ['life', 'learning']\n",
    "corpus = {\"Document 1\": \"The game of life is a game of everlasting learning\", \n",
    "          \"Document 2\": \"The unexamined life is not worth living\", \n",
    "          \"Document 3\": \"Never stop learning\"}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "860613a2-f92f-43c8-b826-24bf22f52f9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary = vocabulary)\n",
    "tfs = tfidf.fit_transform(corpus.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e1549a-d449-4046-9d72-e772453d2d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3bdd57f-d603-486a-ba5e-8b3ac80206d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_index = [header for header in corpus]\n",
    "df = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a67620-f46c-4765-be12-6fc2a1cafe3c",
   "metadata": {},
   "source": [
    "---\n",
    "## TF-IDF dla zlematyzowanego korpusu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf95f09-4f22-42d9-b69a-1747410fffd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(counted_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e01c22c2-b574-47f6-b769-dfd201be06c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "vocabulary = list(filter(lambda x: x[1]>1, counted_words) )\n",
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdb8ceea-eb8e-46d0-91e7-1beb0536874d",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(map(itemgetter(0), vocabulary) )\n",
    "print(vocabulary[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53ef2d61-2ad7-4205-8a7c-d81ce5e16bb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(filter(lambda x: len(x)>2, vocabulary))\n",
    "print(vocabulary[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c80f60-4e33-45a2-a359-7f60336f412f",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08292324-7b07-4fec-86f0-39f055e77dd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary = list(filter(lambda x: x.isnumeric() is False, vocabulary))\n",
    "print(vocabulary[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b817b136-6a0b-4d25-93de-1c71801a27bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b659abe-7eef-48ff-9097-1397a0900ea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary = vocabulary)\n",
    "tfs = tfidf.fit_transform(corpus.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39a4df8f-4744-4bd8-a53a-a05a079b2246",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_vocabulary = set(vocabulary)\n",
    "\n",
    "corpus = [ [ word for word in document if word in set_vocabulary ] for document in corpusl  ]\n",
    "for text in corpus[:7]:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eb39c5d-bee0-4855-816d-5eb08251eb18",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [ ' '.join(document) for document in corpus ] \n",
    "for text in corpus[:7]:\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e430b3f-35c2-48ae-8ab8-7a516d5993bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary = vocabulary)\n",
    "tfs = tfidf.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbc4b847-8ab7-4b17-8206-0ea9790b8d31",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_names = tfidf.get_feature_names()\n",
    "print(feature_names[:50])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fa8b82d-c509-4790-8ac4-c1f81ab7887e",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_index = range(len(corpus))\n",
    "df = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fee4fc0-7891-40d7-bf6b-335ce097df5d",
   "metadata": {},
   "source": [
    "---\n",
    "## Stop words/Stoplista"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecd162b8-d7f8-4398-880f-f44fe002c061",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(vocabulary = vocabulary, stop_words=vocabulary[:50])\n",
    "tfs = tfidf.fit_transform(corpus)\n",
    "feature_names = tfidf.get_feature_names()\n",
    "corpus_index = range(len(corpus))\n",
    "df = pd.DataFrame(tfs.T.todense(), index=feature_names, columns=corpus_index)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef300bf-2894-45d1-aa45-480890418b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(df[6])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e8acc7-84da-457e-9ec9-ca9de77bfa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.loc[~(df==0).all(axis=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15624d7e-972a-4e5e-b622-b715b599a2c5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
